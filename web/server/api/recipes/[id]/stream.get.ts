import { jobStore } from '../../../utils/jobs'
import { logger } from '../../../utils/logger'

export default defineEventHandler(async (event) => {
  const rawRecipeId = getRouterParam(event, 'id')

  const userId = await requireAuth(event)

  if (!rawRecipeId) {
    logger.sse.warn('âŒ Missing recipe ID')
    throw createError({ statusCode: 400, statusMessage: 'Recipe ID is required' })
  }

  // Normalize to lowercase (iOS sends uppercase, Node uses lowercase)
  const recipeId = rawRecipeId.toLowerCase()

  logger.sse.info(`ğŸ”Œ Client connecting - recipeId: ${recipeId}`)

  // Verify ownership before creating stream
  const job = jobStore.get(recipeId)
  if (job && job.userId !== userId) {
    logger.sse.warn(`âŒ Forbidden - job userId mismatch`)
    throw createError({ statusCode: 403, statusMessage: 'Forbidden' })
  }

  logger.sse.debug(`ğŸ“‹ Job status: ${job ? job.status : 'no job in memory'}`)

  const stream = createEventStream(event)

  let closed = false

  const send = async (eventName: string, data: unknown) => {
    if (closed) return
    logger.sse.debug(`ğŸ“¤ Sending event: ${eventName}`)
    await stream.push({
      event: eventName,
      data: JSON.stringify(data)
    })
  }

  const close = async () => {
    if (closed) return
    closed = true
    logger.sse.debug(`ğŸ”š Closing stream`)
    await stream.close()
  }

  // Subscribe to live updates FIRST before replaying to avoid race condition
  const listener = async (eventName: string, data: unknown) => {
    logger.sse.debug(`ğŸ“¡ Listener received: ${eventName}`)
    await send(eventName, data)
    if (eventName === 'complete' || eventName === 'error') {
      logger.sse.info(`ğŸ Terminal event, closing`)
      jobStore.unsubscribe(recipeId, listener)
      await close()
    }
  }

  logger.sse.debug(`ğŸ‘‚ Subscribing to job events`)
  jobStore.subscribe(recipeId, listener)

  // Clean up on disconnect
  stream.onClosed(async () => {
    logger.sse.info(`ğŸ”Œ Client disconnected`)
    jobStore.unsubscribe(recipeId, listener)
  })

  // Start async work to replay events and handle completion
  ;(async () => {
    // Send a test event immediately to verify connection
    logger.sse.debug(`âœ… Sending test event`)
    await stream.push({
      event: 'test',
      data: JSON.stringify({ message: 'Connection established' })
    })
    // Check if extraction already completed (reconnection case)
    if (job) {
      logger.sse.debug(`ğŸ”„ Found job - status: ${job.status}, progress: ${job.progress.length}`)
      // Replay any past progress events
      for (const progress of job.progress) {
        logger.sse.debug(`ğŸ”„ Replaying: ${progress.stage}`)
        await send('progress', progress)
      }

      // If already done, emit final event immediately
      if (job.status === 'pending_review' && job.result) {
        logger.sse.info(`âœ… Job already complete`)
        await send('complete', job.result)
        await close()
        return
      }
      if (job.status === 'failed') {
        logger.sse.warn(`âŒ Job already failed`)
        await send('error', { reason: job.error || 'Extraction failed' })
        await close()
        return
      }
      logger.sse.debug(`â³ Job in progress, waiting...`)
    } else {
      logger.sse.debug(`ğŸ” No job in memory, checking DB...`)
      // No in-memory job â€” check database for already-completed extraction
      const supabase = useSupabaseAdmin()
      const { data: recipe } = await supabase
        .from('recipes')
        .select('status, ingredients, steps, tags')
        .eq('id', recipeId)
        .eq('user_id', userId)
        .single()

      logger.sse.debug(`ğŸ“¦ DB status: ${recipe?.status || 'not found'}`)

      if (recipe?.status === 'pending_review' || recipe?.status === 'active') {
        logger.sse.info(`âœ… Recipe complete in DB`)
        await send('complete', {
          ingredients: recipe.ingredients || [],
          steps: recipe.steps || [],
          tags: recipe.tags || []
        })
        await close()
        return
      }

      if (recipe?.status === 'failed') {
        logger.sse.warn(`âŒ Recipe failed in DB`)
        await send('error', { reason: 'Extraction failed' })
        await close()
        return
      }

      // Recipe not found or stuck in 'importing' without an active job
      if (!recipe) {
        logger.sse.warn(`âŒ Recipe not found`)
        await send('error', { reason: 'Recipe not found' })
        await close()
        return
      }
      if (recipe.status === 'importing') {
        logger.sse.warn(`âš ï¸ Recipe stuck in importing`)
        await send('error', { reason: 'Extraction expired, please re-import' })
        await close()
        return
      }
    }

    // Re-check job status after subscribing to avoid race condition
    const updatedJob = jobStore.get(recipeId)
    logger.sse.debug(`ğŸ”„ Re-check: ${updatedJob?.status || 'no job'}`)
    if (updatedJob?.status === 'pending_review' && updatedJob.result) {
      logger.sse.info(`âœ… Job completed during setup`)
      await send('complete', updatedJob.result)
      jobStore.unsubscribe(recipeId, listener)
      await close()
      return
    }
    if (updatedJob?.status === 'failed') {
      logger.sse.warn(`âŒ Job failed during setup`)
      await send('error', { reason: updatedJob.error || 'Extraction failed' })
      jobStore.unsubscribe(recipeId, listener)
      await close()
      return
    }
    logger.sse.info(`âœ… Stream ready`)
  })().catch(async (err) => {
    logger.sse.error('âŒ Async handler error:', err)
    try {
      await send('error', { reason: 'Internal error' })
      await close()
    } catch {
      // Stream may already be closed
    }
  })

  // Return the stream immediately to establish the connection
  return stream.send()
})
